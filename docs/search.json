[{"path":"index.html","id":"about","chapter":"\n1 About\n","heading":"\n1 About\n","text":"sample book written Markdown. can use anything Pandoc’s Markdown supports; example, math equation \\(^2 + b^2 = c^2\\).","code":""},{"path":"index.html","id":"usage","chapter":"\n1 About\n","heading":"\n1.1 Usage\n","text":"bookdown chapter .Rmd file, .Rmd file can contain one (one) chapter. chapter must start first-level heading: # good chapter, can contain one (one) first-level heading.Use second-level higher headings within chapters like: ## short section ### even shorter section.index.Rmd file required, also first book chapter. homepage render book.","code":""},{"path":"index.html","id":"render-book","chapter":"\n1 About\n","heading":"\n1.2 Render book\n","text":"can render HTML version example book without changing anything:Find Build pane RStudio IDE, andFind Build pane RStudio IDE, andClick Build Book, select output format, select “formats” ’d like use multiple formats book source files.Click Build Book, select output format, select “formats” ’d like use multiple formats book source files.build book R console:render example PDF bookdown::pdf_book, ’ll need install XeLaTeX. recommended install TinyTeX (includes XeLaTeX): https://yihui.org/tinytex/.","code":"\n\nbookdown::render_book()"},{"path":"index.html","id":"preview-book","chapter":"\n1 About\n","heading":"\n1.3 Preview book\n","text":"work, may start local server live preview HTML book. preview update edit book save individual .Rmd files. can start server work session using RStudio add-“Preview book”, R console:","code":"\n\nbookdown::serve_book()"},{"path":"activity-1.html","id":"activity-1","chapter":"2 Activity 1","heading":"2 Activity 1","text":"","code":"\n\nurl <- 'https://www.dropbox.com/scl/fi/2mufv5tlloz06k5ncwyx8/Afternoon_Walk.gpx?rlkey=6jzq31fonrs95glnfibi7lscp&dl=1'\n\nst_layers(url)\ndata <- st_read(url, layer = \"track_points\")"},{"path":"activity-1.html","id":"plotmap-your-movement-data.-i-would-recommend-using-r-andor-google-earth-as-i-demonstrated-in-class.","chapter":"2 Activity 1","heading":"2.1 Plot/map your movement data. I would recommend using R and/or Google earth as I demonstrated in class.","text":"","code":"\ncoords <- as.data.frame(st_coordinates(data))\ncoords$time <- data$time\n\nleaflet(coords) %>% \n  addTiles(group = \"OSM (default)\") %>% \n  addProviderTiles(providers$Esri.WorldImagery, group = \"World Imagery\") %>% \n  addCircleMarkers(~X, ~Y, color = ~time, radius = 2, fillOpacity = .8, group = \"Data Points\") %>% \n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"World Imagery\"),\n    overlayGroups = c(\"Data Points\"),\n    options = layersControlOptions(collapsed = FALSE)\n  )"},{"path":"activity-1.html","id":"explore-your-movement-data.-for-example-are-there-any-unique-features-of-your-data-e.g.-a-large-change-in-location-do-your-data-contain-location-error-really-try-to-explore-your-data-as-best-as-possible-using-the-plotsmaps-you-made-in-3.","chapter":"2 Activity 1","heading":"2.2 Explore your movement data. For example, are there any unique features of your data (e.g., a large change in location)? Do your data contain location error? Really try to explore your data as best as possible using the plots/maps you made in 3.","text":"data actually pretty good. just problems beginning inside building probably carrier service good.","code":"\ntime <- as_datetime(coords$time) - as_datetime(coords$time)[1]\nele <- data$ele\n\ndf <- data.frame(long = coords[,1], \n                 lat = coords[,2],\n                 time = time,\n                 ele = ele)\n\ndf %>% pivot_longer(cols = c(long,lat,ele)) %>% \n  ggplot()+\n  geom_point(aes(time,value), size = 2, shape = 21, fill = 'steelblue', alpha = .8)+\n  facet_wrap(~name, scales = 'free')"},{"path":"activity-1.html","id":"fit-a-statistical-or-machine-learning-model-to-your-movement-data.-obtain-predictions-of-your-location-on-a-fine-time-scale-so-that-the-estimates-resemble-a-continuous-trajectory.","chapter":"2 Activity 1","heading":"2.3 Fit a statistical or machine learning model to your movement data. Obtain predictions of your location on a fine time scale so that the estimates resemble a continuous trajectory.","text":"","code":"\n# Fit models polynomial regression and random forest.\n\n# Longitude\nm1_long <- lm(long ~ poly(time,degree=10,raw=TRUE),data=df)\nsummary(m1_long)\nm2_long <- randomForest(long ~ time, data = df)\nsummary(m2_long)\n\n# Latitude\nm1_lat <- lm(lat ~ poly(time,degree=10,raw=TRUE),data=df)\nsummary(m1_lat)\nm2_lat <- randomForest(lat ~ time, data = df)\nsummary(m2_lat)\n\n# Elevation\nm1_ele <- lm(ele ~ poly(time,degree=10,raw=TRUE),data=df)\nsummary(m1_lat)\nm2_ele <- randomForest(ele ~ time, data = df)\nsummary(m2_lat)"},{"path":"activity-1.html","id":"plotmap-your-estimated-trajectory-from-5.-explore-your-estimated-trajectory-as-best-as-possible-using-the-plotsmaps.-note-any-unique-features-or-shortcomings-of-your-model.","chapter":"2 Activity 1","heading":"2.4 Plot/map your estimated trajectory from 5. Explore your estimated trajectory as best as possible using the plots/maps. Note any unique features or shortcomings of your model.","text":"","code":"\ndf.pred = data.frame(time = seq(0,as.integer(max(df$time))))\n\ndf.pred$long.m1.hat = predict(m1_long, newdata = df.pred)\ndf.pred$long.m2.hat = predict(m2_long, newdata = df.pred)\n\ndf.pred$lat.m1.hat = predict(m1_lat, newdata = df.pred)\ndf.pred$lat.m2.hat = predict(m2_lat, newdata = df.pred)\n\ndf.pred$ele.m1.hat = predict(m1_ele, newdata = df.pred)\ndf.pred$ele.m2.hat = predict(m2_ele, newdata = df.pred)\n\np1 <- ggplot()+\n  geom_point(data = df, aes(time, long), size = 3)+\n  geom_line(data = df.pred, aes(time, long.m1.hat), color = \"gold\", size = 1)+\n  geom_line(data = df.pred, aes(time, long.m2.hat), color = \"red4\", size = 1)\n\np2 <- ggplot()+\n  geom_point(data = df, aes(time, lat), size = 3)+\n  geom_line(data = df.pred, aes(time, lat.m1.hat), color = \"gold\", size = 1)+\n  geom_line(data = df.pred, aes(time, lat.m2.hat), color = \"red4\", size = 1)\n\np3 <- ggplot()+\n  geom_point(data = df, aes(time, ele), size = 3)+\n  geom_line(data = df.pred, aes(time, ele.m1.hat), color = \"gold\", size = 1)+\n  geom_line(data = df.pred, aes(time, ele.m2.hat), color = \"red4\", size = 1)\n\n\nggarrange(p1, p2, p3, nrow = 1)\n# Create data frame for plotting\ndf.pred2 <- df.pred %>% pivot_longer(cols = c(long.m1.hat,long.m2.hat), values_to = 'longitude', names_to = 'model') %>% \n  pivot_longer(cols = c(lat.m1.hat, lat.m2.hat), values_to = 'latitude', names_to = 'model2') %>% \n  mutate(model = substr(model, 6,7),\n         model2 = substr(model2, 5,6)) %>% \n  filter(model == model2) %>% dplyr::select(-c(ele.m1.hat, ele.m2.hat, model2))\n\n# Visualize models\n\ncolor_palette <- colorFactor(palette = \"Set1\", domain = df.pred2$model)\n\nleaflet(df.pred2) %>%\n  addTiles(group = \"OSM (default)\") %>%\n  addProviderTiles(providers$Esri.WorldImagery, group = \"World Imagery\") %>%\n  addCircleMarkers(\n    ~longitude,\n    ~latitude,\n    fillColor = ~color_palette(model), \n    color = ~'black', # This will set the border color the same as the fill color\n    radius = 3,\n    weight = 1,\n    fillOpacity = 0.8,\n    stroke = TRUE, # Set to TRUE to have borders on the circles\n    group = \"Data Points\"\n  ) %>%\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"World Imagery\"),\n    overlayGroups = c(\"Data Points\"),\n    options = layersControlOptions(collapsed = FALSE)\n  ) %>%\n  addLegend(\n    position = \"bottomright\",\n    pal = color_palette,\n    values = ~model,\n    title = \"Model\",\n    opacity = 1.0\n  )"},{"path":"activity-1.html","id":"estimate-a-feature-or-quantity-of-interest-from-your-estimated-trajectory-e.g.-velocity-residence-time-number-of-contacts-etc","chapter":"2 Activity 1","heading":"2.5 Estimate a feature or quantity of interest from your estimated trajectory (e.g., velocity, residence time, number of contacts, etc)","text":"","code":"\n# Calculate speed observed data\ndist <- st_distance(data$geometry[1:701], data$geometry[2:702], by_element = T)\n(sum(dist)/1000)*.62 # Distance observed in km\n#> 2.491147 [m]\nspeed <- (dist/as.numeric(diff(data$time)))*2.24\nplot(df$time[-1], speed)\n\n#Convert model coordinates to sf object\ndata.hat.m1 <- st_as_sf(df.pred, coords = c(\"long.m1.hat\", \"lat.m1.hat\"), \n                           crs = st_crs(data))\n\ndata.hat.m2 <- st_as_sf(df.pred, coords = c(\"long.m2.hat\", \"lat.m2.hat\"), \n                           crs = st_crs(data))\n\n# Calculate speed m1\ndist.hat.m1 <- st_distance(data.hat.m1$geometry[1:741], data.hat.m1$geometry[2:742], by_element = T)\n(sum(dist.hat.m1)/1000)*.62 # Distance in km model 1\n#> 2.576969 [m]\nspeed.hat.m1 <- (dist.hat.m1/as.numeric(diff(data.hat.m1$time)))*2.24\nplot(data.hat.m1$time[-1], speed.hat.m1,xlab=\"Time (seconds)\",ylab=\"Velocity (miles per hour)\", main = 'Polynomial regression')\n\n# Calculate speed m2\ndist.hat.m2 <- st_distance(data.hat.m2$geometry[1:741], data.hat.m2$geometry[2:742], by_element = T)\n(sum(dist.hat.m2)/1000)*.62 # Distance in km model 2\n#> 2.437785 [m]\nspeed.hat.m2 <- (dist.hat.m2/as.numeric(diff(data.hat.m2$time)))*2.24\nplot(data.hat.m2$time[-1], speed.hat.m2,xlab=\"Time (seconds)\",ylab=\"Velocity (miles per hour)\", main = 'Random Forest')"},{"path":"activity-2.html","id":"activity-2","chapter":"3 Activity 2","heading":"3 Activity 2","text":"","code":""},{"path":"activity-2.html","id":"chose-an-area-on-or-close-to-campus-where-it-is-easy-for-you-to-understand-how-the-elevation-changes.-for-example-i-chose-the-parking-lot-outside-of-dickens-hall.-using-a-smartphone-record-the-elevation-at-several-locations-points-within-the-area-you-chose.-i-recommend-using-the-app-strava-but-you-can-use-whatever-you-want.","chapter":"3 Activity 2","heading":"3.1 Chose an area on or close to campus where it is easy for you to understand how the elevation changes. For example, I chose the parking lot outside of Dickens Hall. Using a smartphone record the elevation at several locations (points) within the area you chose. I recommend using the app Strava, but you can use whatever you want.","text":"decided use harvest map retrieved combine dad’s farm. used operate combine know field well. believe meet requirements. Also, required information available, coordinates, elevation time.","code":""},{"path":"activity-2.html","id":"obtain-a-.gpx-or-.csv-file-for-your-elevation-data.-at-minimum-the-file-should-contain-the-location-and-time-of-the-elevation-measurements.","chapter":"3 Activity 2","heading":"3.2 Obtain a .gpx or .csv file for your elevation data. At minimum the file should contain the location and time of the elevation measurements.","text":"Upload data","code":"\n# Points\npoints <-  st_read('https://www.dropbox.com/scl/fi/5km5t8yzjqh9fltq5wz2f/soybean23map.geojson?rlkey=7k2ppf8hl9v4oq4nxvx6n2ket&st=xhmxfx42&dl=1') %>% \n  dplyr::select(Elevation, geometry, Time) %>% \n  .[sample(nrow(.), 100), ] \n#> Reading layer `OGRGeoJSON' from data source \n#>   `https://www.dropbox.com/scl/fi/5km5t8yzjqh9fltq5wz2f/soybean23map.geojson?rlkey=7k2ppf8hl9v4oq4nxvx6n2ket&st=xhmxfx42&dl=1' \n#>   using driver `GeoJSON'\n#> Simple feature collection with 25601 features and 13 fields\n#> Geometry type: POINT\n#> Dimension:     XY\n#> Bounding box:  xmin: 314352.5 ymin: 6696958 xmax: 314835.8 ymax: 6697787\n#> Projected CRS: WGS 84 / UTM zone 22S\n# There are thousands of points, so for the purpose of this activity only a few will be utilized randomly.\n\n# Polygon\npolygon <- st_read('https://www.dropbox.com/scl/fi/bxbwxmgs22yx17j2g8m3y/pol.geojson?rlkey=lx39y99fewf8qgzfh87p0ptmp&st=ngala0hj&dl=1')\n#> Reading layer `OGRGeoJSON' from data source \n#>   `https://www.dropbox.com/scl/fi/bxbwxmgs22yx17j2g8m3y/pol.geojson?rlkey=lx39y99fewf8qgzfh87p0ptmp&st=ngala0hj&dl=1' \n#>   using driver `GeoJSON'\n#> Simple feature collection with 1 feature and 3 fields\n#> Geometry type: POLYGON\n#> Dimension:     XY\n#> Bounding box:  xmin: -5891219 ymin: -3483519 xmax: -5890641 ymax: -3482545\n#> Projected CRS: WGS 84 / Pseudo-Mercator"},{"path":"activity-2.html","id":"plotmap-your-elevation-data.-i-would-recommend-using-r-andor-google-earth.","chapter":"3 Activity 2","heading":"3.3 Plot/map your elevation data. I would recommend using R and/or Google earth.","text":"","code":"\nggplot()+\n  geom_sf(data = polygon)+\n  geom_sf(data = points, aes(fill = Elevation), shape = 21)+\n  scale_fill_viridis_c()+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))"},{"path":"activity-2.html","id":"explore-your-elevation-data.-for-example-are-there-any-unique-features-of-your-data-do-your-data-contain-obvious-measurement-error-e.g.-an-elevation-that-cant-possibly-be-true-really-try-to-explore-your-data-as-best-as-possible-using-the-plotsmaps-you-made-in-.","chapter":"3 Activity 2","heading":"3.4 Explore your elevation data. For example, are there any unique features of your data? Do your data contain obvious measurement error (e.g., an elevation that can’t possibly be true)? Really try to explore your data as best as possible using the plots/maps you made in .","text":"","code":"\nggplot()+\n  geom_histogram(data = points, aes(x = Elevation), \n                 bins = 25, \n                 color = 'black',\n                 fill = 'tomato4',\n                 alpha = .5)+\n  theme_bw()+\n  theme(panel.grid = element_blank())"},{"path":"activity-2.html","id":"write-out-the-goals-that-you-wish-to-accomplish-using-your-elevation-data.-for-example-my-goal-was-to-make-a-map-of-the-dickens-hall-parking-lot.-this-involves-using-the-elevation-data-i-collected-to-make-predictions-of-the-elevation-at-any-possible-spatial-locations-within-the-parking-lot.-i-would-also-like-to-make-inference-about-the-location-where-the-elevation-is-lowest-within-the-parking-lot.","chapter":"3 Activity 2","heading":"3.5 Write out the goals that you wish to accomplish using your elevation data. For example, my goal was to make a map of the Dicken’s Hall parking lot. This involves using the elevation data I collected to make predictions of the elevation at any possible spatial locations within the parking lot. I would also like to make inference about the location where the elevation is lowest within the parking lot.","text":"goal make predictions elevation location field also make inference elevation highest.","code":""},{"path":"activity-2.html","id":"write-out-several-statistical-or-machine-learning-models-that-you-think-you-can-use-to-answer-the-questionsgoals-you-wrote-in-prompt-5.-be-as-creative-and-inclusive-here.-for-each-statistical-or-machine-learning-model-make-sure-you-explain-each-component-piece-of-the-model","chapter":"3 Activity 2","heading":"3.6 Write out several statistical or machine learning models that you think you can use to answer the questions/goals you wrote in prompt #5. Be as creative and inclusive here. For each statistical or machine learning model, make sure you explain each component (piece) of the model","text":"Model 1 - Random Forest\\(\\hat{y}(\\textbf{X}) = \\frac{1}{B} \\sum_{b=1}^B T_b (\\textbf{X})\\)\\(B\\): number trees forest.\\(T_b(\\textbf{X})\\): prediction b-th tree input \\(X\\).\\(\\hat{y}(\\textbf{X})\\): final prediction random forest input \\(X\\).Model 2 - KrigingData Model\\(Y(s_i) = m(s_i) + \\epsilon(s_i)\\)\\(\\epsilon(s_i) \\sim N(0, \\sigma^2)\\)Process Model\\(\\hat{Y}(s_0) \\sim m(s_0) + \\sum_{=1}^{n} \\lambda_i [Y(s_i) - m(s_i)]\\)\\(\\hat{Y}(s_0)\\) represents predicted elevation new location \\(s_0\\).\\(m(s_0)\\) estimated mean trend new location \\(s_0\\).\\(Y(s_i)\\) observed elevations known locations \\(s_i\\).\\({\\lambda}_i\\) weights calculated minimize variance prediction error, based spatial autocorrelation structure.\\(m(s_i)\\) mean trend observed locations.\\(n\\) number observed locations used predictions.","code":""},{"path":"activity-2.html","id":"of-the-models-you-developed-in-prompt-6-find-or-develop-software-to-fit-at-least-two-of-these-models-to-your-elevation-data.-note-that-in-a-perfect-world-you-would-be-able-to-either-find-existing-software-or-develop-new-programs-that-enable-you-to-fit-any-statistical-or-machine-learning-model-you-want.-in-reality-you-may-may-end-up-having-to-make-some-unwanted-changes-to-your-models-in-prompt-6-to-be-able-to-find-existing-software-to-fit-these-models-to-the-data.","chapter":"3 Activity 2","heading":"3.7 7). Of the models you developed in prompt #6, find (or develop) software to fit at least two of these models to your elevation data. Note that in a perfect world, you would be able to either find existing software or develop new programs that enable you to fit any statistical or machine learning model you want. In reality, you may may end up having to make some unwanted changes to your models in prompt #6 to be able to find existing software to fit these models to the data.","text":"KrigingRandom Forest","code":"\n\n# Create random points\nnewPoints <- st_sample(polygon, size = 10000, type = \"random\") %>% \n  as(., 'Spatial') %>% \n  spTransform(., CRS(proj4string(points %>% as(.,'Spatial'))))\npoints\n#> Simple feature collection with 100 features and 2 fields\n#> Geometry type: POINT\n#> Dimension:     XY\n#> Bounding box:  xmin: 314356.1 ymin: 6696981 xmax: 314828.5 ymax: 6697785\n#> Projected CRS: WGS 84 / UTM zone 22S\n#> First 10 features:\n#>       Elevation                Time\n#> 18847  46.69362 4/8/2023 7:40:08 PM\n#> 18895  48.92382 4/8/2023 7:40:56 PM\n#> 25102  61.36804 4/8/2023 9:41:34 PM\n#> 2986   66.15939 4/8/2023 2:30:08 PM\n#> 1842   50.01868 4/8/2023 2:04:36 PM\n#> 3371   50.05362 4/8/2023 2:36:33 PM\n#> 11638  71.28713 4/8/2023 5:14:48 PM\n#> 4761   60.44254 4/8/2023 3:03:38 PM\n#> 6746   58.86041 4/8/2023 3:42:34 PM\n#> 16128  43.89501 4/8/2023 6:46:11 PM\n#>                       geometry\n#> 18847 POINT (314620.2 6697715)\n#> 18895 POINT (314630.1 6697657)\n#> 25102 POINT (314639.5 6697339)\n#> 2986  POINT (314557.5 6697202)\n#> 1842  POINT (314484.4 6697654)\n#> 3371  POINT (314492.5 6697664)\n#> 11638   POINT (314446 6697021)\n#> 4761  POINT (314512.1 6697424)\n#> 6746    POINT (314489 6697471)\n#> 16128 POINT (314655.1 6697785)\n\nkrig.df <- data.frame(ele = points$Elevation,\n                      lon = st_coordinates(points$geometry)[,1],\n                      lat = st_coordinates(points$geometry)[,2])\n\nkrig.mod <- gam(ele ~ s(lon,lat, bs = 'gp'), data = krig.df)\n\nnewpoints.krig <-  as.data.frame(newPoints) %>% \n  rename(\"lon\" = 'coords.x1', \n         'lat' = 'coords.x2')\n\nnewpoints.krig$ele <- predict(krig.mod, newpoints.krig, type = 'response')\ndf.rf <- as.data.frame(points)\ndf.rf$lon <- st_coordinates(points)[,1]\ndf.rf$lat <- st_coordinates(points)[,2]\n\nrf.fit <- randomForest(Elevation ~ lon + lat, data=df.rf, ntree=500, importance=TRUE)\n\nplot(rf.fit)\n\nnewPoints.rf <- as.data.frame(newPoints) %>% \n  rename(\"lon\" = 'coords.x1', \n         'lat' = 'coords.x2')\n\npred.rf <- predict(rf.fit, newPoints.rf) %>% as.data.frame()\n\nnewPoints.rf$ele <- pred.rf$."},{"path":"activity-2.html","id":"related-to-prompt-5-use-both-models-you-fit-to-your-elevation-data-in-prompt-7-to-answer-the-questionsgoals.-for-my-elevation-data-this-would-include-making-a-predictive-heatmap-showing-the-elevation-of-the-dickens-hall-parking-lot-and-then-estimating-the-coordinates-of-the-point-where-elevation-is-at-a-minimum.","chapter":"3 Activity 2","heading":"3.8 Related to prompt #5, use both models you fit to your elevation data in prompt #7 to answer the questions/goals. For my elevation data, this would include making a predictive heatmap showing the elevation of the Dickens Hall parking lot and then estimating the coordinates of the point where elevation is at a minimum.","text":"KrigingRandom Forest","code":"\nkrig.sf <- st_as_sf(newpoints.krig, coords = c('lon','lat'), crs = st_crs(points))\n\nggplot()+\n  geom_sf(data = krig.sf, aes(fill = ele), \n          shape = 21)+\n    geom_sf(data = polygon, fill = NA, color = 'black')+\n  geom_sf(data = krig.sf %>% filter(ele == max(ele)), fill = 'darkred', shape = 22,\n          size = 3)+\n  scale_fill_viridis_c()+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))\nrf.sf <- st_as_sf(newPoints.rf, coords = c('lon','lat'), crs = st_crs(points))\n\nggplot()+\n  geom_sf(data = rf.sf, aes(fill = ele), \n          shape = 21)+\n    geom_sf(data = polygon, fill = NA, color = 'black')+\n  geom_sf(data = krig.sf %>% filter(ele == max(ele)), fill = 'darkred', shape = 22,\n          size = 3)+\n  scale_fill_viridis_c()+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))"},{"path":"activity-2.html","id":"based-on-the-material-in-chapter-6-of-spatio-temporal-statistics-with-r-and-our-discussion-in-class-on-march-26-compare-check-and-evaluate-the-two-models-from-8.","chapter":"3 Activity 2","heading":"3.9 Based on the material in Chapter 6 of Spatio-Temporal Statistics with R and our discussion in class on March 26, compare, check and evaluate the two models from #8.","text":"","code":"\n# Obtain new points at the same area for model testing.\nnewpoints.test <- st_read('https://www.dropbox.com/scl/fi/5km5t8yzjqh9fltq5wz2f/soybean23map.geojson?rlkey=7k2ppf8hl9v4oq4nxvx6n2ket&st=xhmxfx42&dl=1') %>% \n  dplyr::select(Elevation, geometry, Time) %>% \n  .[sample(nrow(.), 100), ]\n#> Reading layer `OGRGeoJSON' from data source \n#>   `https://www.dropbox.com/scl/fi/5km5t8yzjqh9fltq5wz2f/soybean23map.geojson?rlkey=7k2ppf8hl9v4oq4nxvx6n2ket&st=xhmxfx42&dl=1' \n#>   using driver `GeoJSON'\n#> Simple feature collection with 25601 features and 13 fields\n#> Geometry type: POINT\n#> Dimension:     XY\n#> Bounding box:  xmin: 314352.5 ymin: 6696958 xmax: 314835.8 ymax: 6697787\n#> Projected CRS: WGS 84 / UTM zone 22S\n\n# Plot training and testing datasets\nggplot()+\n  geom_sf(data = polygon)+\n  geom_sf(data = points, shape = 21, fill = 'gold')+\n  geom_sf(data = newpoints.test, shape = 22, fill = 'pink4')+\n  scale_fill_viridis_c()+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))\n# Predictions\ntest.df <- data.frame(ele = newpoints.test$Elevation,\n                      lon = st_coordinates(newpoints.test$geometry)[,1],\n                      lat = st_coordinates(newpoints.test$geometry)[,2])\n\ntest.df$pred.krig <- predict(krig.mod, newdata = test.df, type = 'response')\ntest.df$pred.rf <- predict(rf.fit, newdata = test.df)\nrmse.krig <- rmse(test.df$ele, as.numeric(test.df$pred.krig))\nmae.krig <- mae(test.df$ele, as.numeric(test.df$pred.krig))\n\nrmse.rf <- rmse(test.df$ele, as.numeric(test.df$pred.rf))\nmae.rf <- mae(test.df$ele, as.numeric(test.df$pred.rf))\n\n#Kriging metrics\n\nkrigingMetrics <- test.df %>% \n  ggplot()+\n  geom_point(aes(pred.krig, ele), fill = 'purple4', color = 'black', shape = 21, size = 2,\n             alpha = .7)+\n  geom_abline(slope = 1)+\n  #scale_y_continuous(limits = c(0,90), breaks = seq(0,100, 20))+\n  #scale_x_continuous(limits = c(0,90), breaks = seq(0,100, 20))+\n  theme_bw()+\n  labs(title = 'Kriging', x = 'Predicted', y = 'Observed')+\n  annotate('text', label = paste0('RMSE: ', round(rmse.krig,1)), x = 65, y = 50)+\n  annotate('text', label = paste0('MAE: ', round(mae.krig,1)), x = 65, y = 48)+\n  theme(panel.grid = element_blank(),\n        aspect.ratio = 1,\n        text = element_text(size = 12)\n        )\n\n#Rf metrics\n\nrfMetrics <- test.df %>% \n  ggplot()+\n  geom_point(aes(pred.rf, ele), fill = 'purple4', color = 'black', shape = 21, size = 2,\n             alpha = .7)+\n  geom_abline(slope = 1)+\n  #scale_y_continuous(limits = c(0,90), breaks = seq(0,100, 20))+\n  #scale_x_continuous(limits = c(0,90), breaks = seq(0,100, 20))+\n  theme_bw()+\n  labs(title = 'Random Forest', x = 'Predicted', y = 'Observed')+\n  annotate('text', label = paste0('RMSE: ', round(rmse.rf,1)), x = 65, y = 50)+\n  annotate('text', label = paste0('MAE: ', round(mae.rf,1)), x = 65, y = 48)+\n  theme(panel.grid = element_blank(),\n        aspect.ratio = 1,\n        text = element_text(size = 12)\n        )\n\nggarrange(krigingMetrics,rfMetrics)"},{"path":"activity-3.html","id":"activity-3","chapter":"4 Activity 3","heading":"4 Activity 3","text":"","code":""},{"path":"activity-3.html","id":"upload-data","chapter":"4 Activity 3","heading":"4.1 Upload data","text":"","code":"\n# Upload data\nurl <- \"https://www.dropbox.com/scl/fi/9ymxt900s77uq50ca6dgc/Enders-et-al.-2018-data.csv?rlkey=0rxjwleenhgu0gvzow5p0x9xf&dl=1\"\ndf <- read.csv(url)\ndf <- df[,c(2,8:10)] %>% \n  mutate(presence = ifelse(EGA != 0, 1, 0))# Keep only the data on bird cherry-oat aphid\n\n# Download KS shapefile\nks <- raster::getData(name=\"GADM\", country=\"USA\", level=1) %>% \n  st_as_sf() %>% \n  filter(NAME_1 == 'Kansas')\n\ndf_sf <- df %>% st_as_sf(coords = c('long', 'lat'), crs = st_crs(ks))"},{"path":"activity-3.html","id":"upload-covariates","chapter":"4 Activity 3","heading":"4.2 Upload covariates","text":"","code":"\nurl.nlcd <- \"https://www.dropbox.com/scl/fi/ew7yzm93aes7l8l37cn65/KS_2011_NLCD.img?rlkey=60ahyvxhq18gt0yr47tuq5fig&dl=1\"\nrl.nlcd2011 <- raster(url.nlcd)\n\nplot(rl.nlcd2011)\n\n\n# Make raster file that contains pixels with value of 1 if grassland and \n# zero if other type of land cover.\n# NLCD legend can be found here: https://www.mrlc.gov/data/legends/national-land-cover-database-2011-nlcd2011-legend\nrl.nlcd.grass <- rl.nlcd2011\nrl.nlcd.grass[] <- ifelse(rl.nlcd.grass[]==71,1,0)\n\nplot(rl.nlcd.grass)\n\npts.sample<- df\n\ncoordinates(pts.sample) =~ long + lat\nproj4string(pts.sample) <- CRS(\"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\")\n\n# Calculate percentage of land area that is grassland within 5 km of sampled location\ndf$grass.perc <- unlist(lapply(extract(rl.nlcd.grass,pts.sample,buffer=5000),mean))*100\n\nhist(df$grass.perc,col=\"grey\",main=\"\",xlab=\"% grassland within \\n5 km at sample location\")"},{"path":"activity-3.html","id":"for-the-data-on-the-abundance-of-english-grain-aphids-propose-three-different-statistical-models-or-machine-learning-approach-that-are-capable-of-predicting-the-number-of-english-grain-aphids-at-any-location-within-the-state-of-kansas-at-any-time-for-the-years-2014-and-2015.-make-sure-to-write-out-the-three-statistical-models-using-formal-notation-and-fully-describe-each-component-using-words.","chapter":"4 Activity 3","heading":"4.3 For the data on the abundance of English grain aphids, propose three different statistical models (or machine learning approach) that are capable of predicting the number of English grain aphids at any location within the state of Kansas at any time for the years 2014 and 2015. Make sure to write out the three statistical models using formal notation and fully describe each component using words.","text":"Model 1Data model \\[Z = y\\] Process model Using Poisson distribution\\[[y|\\lambda] = Poisson(\\lambda) \\]\\[\\eta_s\\sim MUN(0, \\sigma)\\] \\[\\eta_t\\sim MVN(0, \\sigma)\\]\n\\[E(y)=e^{\\beta_0+\\beta_1\\cdot X~\\eta_s+\\eta_t}\\]Model 2Data model\\[Z = y\\] Process model Using Negative binomial distribution\\[[y|r,p] = NB(r, p)\\] \\[\\eta_s\\sim MVN(0, \\sigma)\\]\n\\[\\eta_t\\sim  MVN(0, \\sigma)\\]\n\\[E(y)=e^{\\beta_0+\\beta_1\\cdot X~\\eta_s+\\eta_t}\\]Model 3Data model\\[Z = y\\] Process model Using zero inflated poisson distribution\\[[y|p, \\lambda]=ZIP(p,\\lambda)\\] \\[\\eta_s\\sim MVN(0, \\sigma^2)\\]\n\\[E(y)=e^{\\beta_0+\\beta_1\\cdot X~\\eta_s+\\eta_t}\\]","code":""},{"path":"activity-3.html","id":"for-the-three-statistical-models-you-proposed-in-question-1-propose-a-way-to-measure-the-accuracy-and-perhaps-the-calibration-of-predictions.","chapter":"4 Activity 3","heading":"4.4 For the three statistical models you proposed in question #1, propose a way to measure the accuracy (and perhaps the calibration) of predictions.","text":"RMSE MAE AIC.","code":""},{"path":"activity-3.html","id":"fit-the-three-statistical-models-you-proposed-in-question-1-to-the-english-grain-aphid-abundance-data.","chapter":"4 Activity 3","heading":"4.5 Fit the three statistical models you proposed in question #1 to the English grain aphid abundance data.","text":"","code":"\n\nggplot()+\n  geom_sf(data = ks)+\n  geom_sf(data = df_sf, shape = 21, aes(size = EGA, fill = factor(presence)))+\n  theme_bw()+\n  facet_wrap(~year, ncol = 1)"},{"path":"activity-3.html","id":"model-1","chapter":"4 Activity 3","heading":"4.5.1 Model 1","text":"","code":"\nm1 <- gam(EGA ~ grass.perc + as.factor(year) + s(long,lat, bs = \"gp\"), \n          family = poisson(link = \"log\"), data = df)\n\nsummary(m1)\n#> \n#> Family: poisson \n#> Link function: log \n#> \n#> Formula:\n#> EGA ~ grass.perc + as.factor(year) + s(long, lat, bs = \"gp\")\n#> \n#> Parametric coefficients:\n#>                       Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)         -3.1624342  0.2629681 -12.026   <2e-16\n#> grass.perc          -0.0084544  0.0009811  -8.617   <2e-16\n#> as.factor(year)2015  5.5241770  0.2584600  21.373   <2e-16\n#>                        \n#> (Intercept)         ***\n#> grass.perc          ***\n#> as.factor(year)2015 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Approximate significance of smooth terms:\n#>               edf Ref.df Chi.sq p-value    \n#> s(long,lat) 31.97     32   8009  <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> R-sq.(adj) =  0.395   Deviance explained = 69.9%\n#> UBRE = 28.333  Scale est. = 1         n = 341"},{"path":"activity-3.html","id":"model-2","chapter":"4 Activity 3","heading":"4.5.2 Model 2","text":"","code":"\nm2 <- gam(EGA ~ grass.perc + as.factor(year) + s(long,lat, bs = \"gp\"), \n          family = nb(theta = NULL,link = \"log\"), data = df)\n\nsummary(m2)\n#> \n#> Family: Negative Binomial(0.623) \n#> Link function: log \n#> \n#> Formula:\n#> EGA ~ grass.perc + as.factor(year) + s(long, lat, bs = \"gp\")\n#> \n#> Parametric coefficients:\n#>                      Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)         -2.512753   0.343910  -7.306 2.74e-13\n#> grass.perc          -0.005170   0.004665  -1.108    0.268\n#> as.factor(year)2015  5.164253   0.325909  15.846  < 2e-16\n#>                        \n#> (Intercept)         ***\n#> grass.perc             \n#> as.factor(year)2015 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Approximate significance of smooth terms:\n#>               edf Ref.df Chi.sq p-value    \n#> s(long,lat) 8.884  11.75  372.1  <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> R-sq.(adj) =  0.247   Deviance explained = 68.6%\n#> -REML = 962.32  Scale est. = 1         n = 341"},{"path":"activity-3.html","id":"model-3","chapter":"4 Activity 3","heading":"4.5.3 Model 3","text":"","code":"\n\nm3 <- gam(list(EGA ~ grass.perc + as.factor(year) + s(long,lat, bs = \"gp\"), ~ grass.perc + s(long,lat, bs = \"gp\")), \n          family = ziplss(), data = df)\n\nsummary(m3)\n#> \n#> Family: ziplss \n#> Link function: identity identity \n#> \n#> Formula:\n#> EGA ~ grass.perc + as.factor(year) + s(long, lat, bs = \"gp\")\n#> ~grass.perc + s(long, lat, bs = \"gp\")\n#> \n#> Parametric coefficients:\n#>                       Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)         -1.5217298  0.3565564  -4.268 1.97e-05\n#> grass.perc          -0.0098653  0.0009923  -9.942  < 2e-16\n#> as.factor(year)2015  4.0446085  0.3513845  11.510  < 2e-16\n#> (Intercept).1       -0.0430138  0.1513463  -0.284    0.776\n#> grass.perc.1         0.0026990  0.0044434   0.607    0.544\n#>                        \n#> (Intercept)         ***\n#> grass.perc          ***\n#> as.factor(year)2015 ***\n#> (Intercept).1          \n#> grass.perc.1           \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Approximate significance of smooth terms:\n#>                 edf Ref.df  Chi.sq  p-value    \n#> s(long,lat)   31.55  31.84 6583.32  < 2e-16 ***\n#> s.1(long,lat) 11.98  15.64   43.45 0.000195 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Deviance explained = 61.3%\n#> -REML = 5369.7  Scale est. = 1         n = 341"},{"path":"activity-3.html","id":"create-points-for-prediction","chapter":"4 Activity 3","heading":"4.6 Create points for prediction","text":"","code":"\n####\nrl.E.y <- raster(,nrow=30,ncols=30,ext=extent(ks),crs=crs(ks))\nnewPoints <- data.frame(long = xyFromCell(rl.E.y,cell=1:length(rl.E.y[]))[,1],\n                      lat = xyFromCell(rl.E.y,cell=1:length(rl.E.y[]))[,2]) %>%\n  st_as_sf(coords = c('long', 'lat'), crs = st_crs(ks)) %>% \n  st_filter(ks) %>% as.data.frame() %>% \n  cross_join(data.frame(year = as.factor(c('2014', '2015'))))\n\nnewPoints$lat <- st_coordinates(newPoints$geometry)[,2]\nnewPoints$long <- st_coordinates(newPoints$geometry)[,1]\n\n# \n# newPoints <- st_sample(ks, size = 1000, type = \"regular\") %>%\n#   as(., 'Spatial') %>% as.data.frame() %>%\n#     rename(\"long\" = 'coords.x1',\n#          'lat' = 'coords.x2') %>%\n#   cross_join(data.frame(year = as.factor(c('2014', '2015'))))\n\n    \npts.sample<- newPoints\n\ncoordinates(pts.sample) =~ long + lat\nproj4string(pts.sample) <- CRS(\"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\")\n\nnewPoints$grass.perc <- unlist(lapply(extract(rl.nlcd.grass,pts.sample,buffer=5000),mean))*100\n# Fit mod 1\nnewPoints$y_pred1 <- predict(m1, newPoints, type = 'response')\n\n# m1.pred <- st_as_sf(newPoints, coords = c('long', 'lat'), crs = st_crs(ks),\n#                     agr = 'constant') \n\nggplot()+\n\n  geom_tile(data = newPoints, aes(x = long, y = lat, fill = y_pred1))+\n    geom_sf(data = ks, fill = NA, color = 'black')+\n  scale_fill_viridis_c(values = c(0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1))+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))+\n  facet_wrap(~year, ncol = 1)\n# Fit mod 2\nnewPoints$y_pred2 <- predict(m2, newPoints, type = 'response')\n\n\nggplot()+\n\n  geom_tile(data = newPoints, aes(x = long, y = lat, fill = y_pred2))+\n    geom_sf(data = ks, fill = NA, color = 'black')+\n  scale_fill_viridis_c()+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))+\n  facet_wrap(~year, ncol = 1)\n# Fit mod 3\nnewPoints$y_pred3 <- predict(m3, newPoints, type = 'response')\n\n# m3.pred <- st_as_sf(newPoints, coords = c('long', 'lat'), crs = st_crs(ks),\n                    # agr = 'constant') \n\nggplot()+\n\n  geom_tile(data = newPoints, aes(x = long, y = lat, fill = y_pred3))+\n    geom_sf(data = ks, fill = NA, color = 'black')+\n  scale_fill_viridis_c(values = c(0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1))+\n  labs(x = 'Longitude', y = 'Latitude')+\n  theme_bw()+\n  theme(axis.text.x = element_text(angle = 30))+\n  facet_wrap(~year, ncol = 1)"},{"path":"activity-3.html","id":"for-the-three-models-you-fit-in-question-3-which-model-makes-the-most-accurate-predictions-how-good-is-the-best-model-in-real-world-terms-remember-we-are-trying-to-predict-the-number-of-english-grain-aphids-which-is-a-count","chapter":"4 Activity 3","heading":"4.7 For the three models you fit in question #3, which model makes the most accurate predictions? How good is the best model in real world terms? Remember we are trying to predict the number of English grain aphids, which is a count!","text":"","code":"\nrmse.m1 <- rmse(df$EGA, as.numeric(predict(m1, df, type = 'response')))\nmae.m1 <- mae(df$EGA, as.numeric(predict(m1, df, type = 'response')))\n\nrmse.m2 <- rmse(df$EGA, as.numeric(predict(m2, df, type = 'response')))\nmae.m2 <- mae(df$EGA, as.numeric(predict(m2, df, type = 'response')))\n\nrmse.m3 <- rmse(df$EGA, as.numeric(predict(m3, df, type = 'response')))\nmae.m3 <- mae(df$EGA, as.numeric(predict(m3, df, type = 'response')))\n\n#m1 metrics\n\nm1Metrics <- df %>% \n  ggplot()+\n  geom_point(aes(predict(m1, df, type = 'response'), EGA), \nfill = 'purple4', color = 'black', shape = 21, size = 2,\n             alpha = .7)+\n  geom_abline(slope = 1)+\n  scale_y_continuous(limits = c(0,1000), breaks = seq(0,1000, 200))+\n  scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000, 200))+  theme_bw()+\n  labs(title = 'm1', x = 'Predicted', y = 'Observed')+\n  annotate('text', label = paste0('RMSE: ', round(rmse.m1,1)), x = 700, y = 200)+\n  annotate('text', label = paste0('MAE: ', round(mae.m1,1)), x = 700, y = 100)+\n  theme(panel.grid = element_blank(),\n        aspect.ratio = 1,\n        text = element_text(size = 12)\n        )\n\n#m2 metrics\n\nm2Metrics <- df %>% \n  ggplot()+\n  geom_point(aes(predict(m2, df, type = 'response'), EGA), \n             fill = 'purple4', color = 'black', shape = 21, size = 2,\n             alpha = .7)+\n  geom_abline(slope = 1)+\n  scale_y_continuous(limits = c(0,1000), breaks = seq(0,1000, 200))+\n  scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000, 200))+  theme_bw()+\n  labs(title = 'm2', x = 'Predicted', y = 'Observed')+\n  annotate('text', label = paste0('RMSE: ', round(rmse.m2,1)), x = 700, y = 200)+\n  annotate('text', label = paste0('MAE: ', round(mae.m2,1)), x = 700, y = 100)+\n  theme(panel.grid = element_blank(),\n        aspect.ratio = 1,\n        text = element_text(size = 12)\n        )\n\nm3Metrics <- df %>% \n  ggplot()+\n  geom_point(aes(predict(m3, df, type = 'response'), EGA), \n             fill = 'purple4', color = 'black', shape = 21, size = 2,\n             alpha = .7)+\n  geom_abline(slope = 1)+\n  scale_y_continuous(limits = c(0,1000), breaks = seq(0,1000, 200))+\n  scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000, 200))+\n  theme_bw()+\n  labs(title = 'm3', x = 'Predicted', y = 'Observed')+\n  annotate('text', label = paste0('RMSE: ', round(rmse.m3,1)), x = 700, y = 200)+\n  annotate('text', label = paste0('MAE: ', round(mae.m3,1)), x = 700, y = 100)+\n  theme(panel.grid = element_blank(),\n        aspect.ratio = 1,\n        text = element_text(size = 12)\n        )\n\nggarrange(m1Metrics,m2Metrics, m3Metrics, nrow = 1)\n\nAIC(m1, m2, m3)\n#>          df       AIC\n#> m1 34.97341 10896.425\n#> m2 13.90150  1913.024\n#> m3 50.09095 10464.469"},{"path":"activity-3.html","id":"summarize-your-results-using-words-numerical-values-and-figuresmaps.","chapter":"4 Activity 3","heading":"4.8 Summarize your results using words, numerical values and figures/maps.","text":"","code":""}]
